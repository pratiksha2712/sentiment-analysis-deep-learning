{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import re\n",
    "import pandas as pd \n",
    "import re\n",
    "import numpy as np\n",
    "from gensim.models import Doc2Vec, doc2vec\n",
    "#import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob, Word\n",
    "import nltk\n",
    "#nltk.download('wordnet')\n",
    "#nltk.download('stopwords')\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       label                                               text\n",
      "0          1  [great, mobile, app, nice, reward, program, ma...\n",
      "1          2  [really, fast, polite, definitely, recommend, ...\n",
      "2          2  [place, always, amazing, friendly, staff, grea...\n",
      "3          1  [wine, 101, class, friday, night, cool, spot, ...\n",
      "4          1  [rounding, think, place, may, potential, coupl...\n",
      "5          0  [romantic, tryst, planet, hollywood, poker, ro...\n",
      "6          2  [got, color, haircut, finally, month, looking,...\n",
      "7          0  [never, go, place, nearly, empty, 430, pm, sat...\n",
      "8          2  [ive, come, 2, year, np, bought, staff, always...\n",
      "9          0  [07082014, war, ich, mit, 5, kollegen, mittags...\n",
      "10         2  [5, star, takeout, recommended, dinein, liquor...\n",
      "11         1  [nachdem, wir, jetzt, da, dritte, mal, vor, de...\n",
      "12         2  [hand, best, polish, boy, sandwich, cleveland,...\n",
      "13         2  [oh, fuzzys, begin, familiar, toby, keith, son...\n",
      "14         2  [ive, tried, many, cupcake, magnolia, prarie, ...\n",
      "15         1  [put, irish, pub, walmart, youd, get, dont, ge...\n",
      "16         2  [amazing, pho, almost, drinking, broth, straw,...\n",
      "17         1  [la, eiffel, tower, en, la, vegaspostaes, eso,...\n",
      "18         2  [love, shop, best, retro, dress, vega, girl, w...\n",
      "19         2  [definitely, sexy, show, surprisingly, funny, ...\n",
      "20         0  [something, must, gone, horribly, wrong, since...\n",
      "21         2  [happy, find, silk, found, nicole, professiona...\n",
      "22         2  [good, get, qdoba, seriously, qdoba, good, tas...\n",
      "23         2  [another, one, favorite, spot, place, awesome,...\n",
      "24         2  [count, charleston, topnotch, food, service, a...\n",
      "25         2  [amazing, place, went, massage, relaxing, staf...\n",
      "26         2  [man, oh, man, place, fucking, bomb, pastor, a...\n",
      "27         1  [great, food, big, portion, excellent, custome...\n",
      "28         2  [son, iphone, 6, screen, busted, fixed, le, ho...\n",
      "29         1  [yes, space, cozy, comfy, food, le, club, chas...\n",
      "...      ...                                                ...\n",
      "399971     0  [came, 12pm, tuesday, theyre, supposed, open, ...\n",
      "399972     2  [pizza, place, delicious, daughter, loved, big...\n",
      "399973     2  [love, place, waiting, row, half, hour, defini...\n",
      "399974     2  [walk, place, 5, day, week, since, november, 1...\n",
      "399975     0  [dont, usually, write, 1, star, moira, deserve...\n",
      "399976     1  [mediocre, food, overpriced, buffet, come, sus...\n",
      "399977     1  [food, fantastic, though, pricier, side, brunc...\n",
      "399978     0  [service, ok, c, 25, food, quick, arrive, wait...\n",
      "399979     0  [la, vega, past, weekend, attend, mountain, we...\n",
      "399980     2  [whatever, need, done, subaru, guy, reliable, ...\n",
      "399981     2  [fantastic, experience, room, indeed, whole, h...\n",
      "399982     2  [well, first, official, verizon, wireless, sto...\n",
      "399983     1  [got, vanilla, spiced, oatmeal, 8, like, 4, sl...\n",
      "399984     2  [place, delightful, food, elegant, tasteful, a...\n",
      "399985     2  [stayed, several, time, management, staff, pol...\n",
      "399986     2  [great, chinese, food, great, place, take, fri...\n",
      "399987     2  [never, 188, forever, continue, coming, back, ...\n",
      "399988     1  [perfectly, adequate, gyro, place, small, clea...\n",
      "399989     2  [ive, used, mbv, least, nine, year, fix, 2000,...\n",
      "399990     0  [dont, bother, coming, back, hadnt, 10, year, ...\n",
      "399991     2  [couldnt, happier, 5th, wine, first, introduce...\n",
      "399992     2  [kasadee, fantastic, hair, stylist, best, ive,...\n",
      "399993     1  [decided, grab, food, fish, chip, thought, pla...\n",
      "399994     1  [hot, dog, 1218, inch, great, frozen, hot, cho...\n",
      "399995     2  [never, used, moving, company, prior, family, ...\n",
      "399996     2  [went, first, time, got, kelsey, dye, cut, hai...\n",
      "399997     2  [first, experience, true, food, kitchen, trip,...\n",
      "399998     2  [must, one, talkedabout, secondhand, bike, pla...\n",
      "399999     2  [undeniably, best, bang, buck, city, 10, buck,...\n",
      "400000     0  [dont, order, hamburger, ordered, well, done, ...\n",
      "\n",
      "[400001 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "df = pd.read_csv('train.csv',dtype={\"label\": object, \"text\": object})\n",
    "#df = pd.read_csv(\"sample.csv\", dtype={\"label\": object, \"text\": object})\n",
    "y = df.label \n",
    "text = df.text\n",
    "\n",
    "#print(df)\n",
    "#Convert all text to lower case\n",
    "df.text = df.text.apply(lambda x: \" \".join(x.lower() for x in str(x).split()))\n",
    "\n",
    "#Remove all punctuation\n",
    "for i in range(0, len(text)):\n",
    "    df.text[i] = re.sub(r'[^\\w\\s]', \"\", df.text[i])\n",
    "    \n",
    "stop = stopwords.words(\"english\")\n",
    "# for i in range(0, len(text)):\n",
    "#   line = text[i].split()\n",
    "#   for word in line:\n",
    "#     if word in stop:\n",
    "#       line.remove(word)\n",
    "#   text[i] = \" \".join(line)\n",
    "      \n",
    "#Remove stop words\n",
    "df.text = df.text.apply(lambda x: \" \".join(x for x in str(x).split() if x not in stop))\n",
    "\n",
    "#Lem\n",
    "df.text = df.text.apply(lambda x: \" \".join(Word(x).lemmatize() for x in x.split()))\n",
    "\n",
    "for i, line in enumerate(df.text):\n",
    "    df.text[i] = line.split()\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "del(data)\n",
    "data = df[['text', 'label']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [great, mobile, app, nice, reward, program, ma...\n",
       "1         [really, fast, polite, definitely, recommend, ...\n",
       "2         [place, always, amazing, friendly, staff, grea...\n",
       "3         [wine, 101, class, friday, night, cool, spot, ...\n",
       "4         [rounding, think, place, may, potential, coupl...\n",
       "5         [romantic, tryst, planet, hollywood, poker, ro...\n",
       "6         [got, color, haircut, finally, month, looking,...\n",
       "7         [never, go, place, nearly, empty, 430, pm, sat...\n",
       "8         [ive, come, 2, year, np, bought, staff, always...\n",
       "9         [07082014, war, ich, mit, 5, kollegen, mittags...\n",
       "10        [5, star, takeout, recommended, dinein, liquor...\n",
       "11        [nachdem, wir, jetzt, da, dritte, mal, vor, de...\n",
       "12        [hand, best, polish, boy, sandwich, cleveland,...\n",
       "13        [oh, fuzzys, begin, familiar, toby, keith, son...\n",
       "14        [ive, tried, many, cupcake, magnolia, prarie, ...\n",
       "15        [put, irish, pub, walmart, youd, get, dont, ge...\n",
       "16        [amazing, pho, almost, drinking, broth, straw,...\n",
       "17        [la, eiffel, tower, en, la, vegaspostaes, eso,...\n",
       "18        [love, shop, best, retro, dress, vega, girl, w...\n",
       "19        [definitely, sexy, show, surprisingly, funny, ...\n",
       "20        [something, must, gone, horribly, wrong, since...\n",
       "21        [happy, find, silk, found, nicole, professiona...\n",
       "22        [good, get, qdoba, seriously, qdoba, good, tas...\n",
       "23        [another, one, favorite, spot, place, awesome,...\n",
       "24        [count, charleston, topnotch, food, service, a...\n",
       "25        [amazing, place, went, massage, relaxing, staf...\n",
       "26        [man, oh, man, place, fucking, bomb, pastor, a...\n",
       "27        [great, food, big, portion, excellent, custome...\n",
       "28        [son, iphone, 6, screen, busted, fixed, le, ho...\n",
       "29        [yes, space, cozy, comfy, food, le, club, chas...\n",
       "                                ...                        \n",
       "399971    [came, 12pm, tuesday, theyre, supposed, open, ...\n",
       "399972    [pizza, place, delicious, daughter, loved, big...\n",
       "399973    [love, place, waiting, row, half, hour, defini...\n",
       "399974    [walk, place, 5, day, week, since, november, 1...\n",
       "399975    [dont, usually, write, 1, star, moira, deserve...\n",
       "399976    [mediocre, food, overpriced, buffet, come, sus...\n",
       "399977    [food, fantastic, though, pricier, side, brunc...\n",
       "399978    [service, ok, c, 25, food, quick, arrive, wait...\n",
       "399979    [la, vega, past, weekend, attend, mountain, we...\n",
       "399980    [whatever, need, done, subaru, guy, reliable, ...\n",
       "399981    [fantastic, experience, room, indeed, whole, h...\n",
       "399982    [well, first, official, verizon, wireless, sto...\n",
       "399983    [got, vanilla, spiced, oatmeal, 8, like, 4, sl...\n",
       "399984    [place, delightful, food, elegant, tasteful, a...\n",
       "399985    [stayed, several, time, management, staff, pol...\n",
       "399986    [great, chinese, food, great, place, take, fri...\n",
       "399987    [never, 188, forever, continue, coming, back, ...\n",
       "399988    [perfectly, adequate, gyro, place, small, clea...\n",
       "399989    [ive, used, mbv, least, nine, year, fix, 2000,...\n",
       "399990    [dont, bother, coming, back, hadnt, 10, year, ...\n",
       "399991    [couldnt, happier, 5th, wine, first, introduce...\n",
       "399992    [kasadee, fantastic, hair, stylist, best, ive,...\n",
       "399993    [decided, grab, food, fish, chip, thought, pla...\n",
       "399994    [hot, dog, 1218, inch, great, frozen, hot, cho...\n",
       "399995    [never, used, moving, company, prior, family, ...\n",
       "399996    [went, first, time, got, kelsey, dye, cut, hai...\n",
       "399997    [first, experience, true, food, kitchen, trip,...\n",
       "399998    [must, one, talkedabout, secondhand, bike, pla...\n",
       "399999    [undeniably, best, bang, buck, city, 10, buck,...\n",
       "400000    [dont, order, hamburger, ordered, well, done, ...\n",
       "Name: text, Length: 400001, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'replace'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-5a2534a2cfd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'replace'"
     ]
    }
   ],
   "source": [
    "for idx,row in data.iterrows():\n",
    "    row[0] = row[0].replace('rt',' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-00432e26c1e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-26-00432e26c1e2>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mvocabulary\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "vocabulary=[]\n",
    "data['text'][0]\n",
    "for key, value in data['text'].items():\n",
    "    temp = value\n",
    "    vocabulary.append(temp)\n",
    "vocabulary\n",
    "vocabulary= [x.encode('ascii')  for x in vocabulary]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'encode'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c7735b94e5ae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-10-c7735b94e5ae>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'ascii'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'text'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'encode'"
     ]
    }
   ],
   "source": [
    "data['text']= [x.encode('ascii') for x in data['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saura/anaconda3/lib/python3.6/site-packages/keras/preprocessing/text.py:172: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
      "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
     ]
    }
   ],
   "source": [
    "tokenizer = Tokenizer(nb_words=2000, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                                   lower=True,split=' ')\n",
    "tokenizer.fit_on_texts(data['text'].values)\n",
    "tokenizer\n",
    "X = tokenizer.texts_to_sequences(data['text'].values)\n",
    "X = pad_sequences(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saura/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: The `dropout` argument is no longer support in `Embedding`. You can apply a `keras.layers.SpatialDropout1D` layer right after the `Embedding` layer to get the same behavior.\n",
      "  \n",
      "/home/saura/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:7: UserWarning: Update your `LSTM` call to the Keras 2 API: `LSTM(196, dropout=0.2, recurrent_dropout=0.2)`\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_6 (Embedding)      (None, 486, 128)          256000    \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 196)               254800    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 4)                 788       \n",
      "=================================================================\n",
      "Total params: 511,588\n",
      "Trainable params: 511,588\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "embed_dim = 128\n",
    "lstm_out = 196\n",
    "batch_size = 32\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, embed_dim,input_length = X.shape[1], dropout = 0.2))\n",
    "model.add(LSTM(lstm_out, dropout_U = 0.2, dropout_W = 0.2))\n",
    "model.add(Dense(units=4,activation='relu'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer='adam',metrics = ['accuracy'])\n",
    "print(model.summary())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0,    0, ...,  411,   40, 1296],\n",
       "       [   0,    0,    0, ...,  115,    9, 1375],\n",
       "       [   0,    0,    0, ...,  312,    3,  196],\n",
       "       ..., \n",
       "       [   0,    0,    0, ...,  277,    3,    1],\n",
       "       [   0,    0,    0, ...,    1,    7,  113],\n",
       "       [   0,    0,    0, ...,   68,  252,   11]], dtype=int32)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400001, 486)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(320000, 486) (320000, 4)\n",
      "(80001, 486) (80001, 4)\n"
     ]
    }
   ],
   "source": [
    "Y = pd.get_dummies(data['label']).values\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size = 0.2, random_state = 42)\n",
    "print(X_train.shape,Y_train.shape)\n",
    "print(X_test.shape,Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/saura/anaconda3/lib/python3.6/site-packages/keras/models.py:981: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "model.fit(X_train, Y_train, batch_size = batch_size, nb_epoch = 1, verbose = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
